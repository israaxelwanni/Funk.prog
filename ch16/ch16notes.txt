16.2
non-overlapping functions = Patterns that do not rely on the order in which 
                            they are matched.

In order to simplify the process of reasoning about programs, 
it is good practice to use non-overlapping patterns whenever 
possible when defining functions

16.4
Haskell programs involve some form of recursion. Reasoning about such programs 
normally proceeds using the simple but powerful technique of induction.

data Nat = Zero | Succ Nat

add :: Nat -> Nat -> Nat
add Zero m = m
add (Succ n) m = Succ (add n m)

Example:
P(n) ::= add n Zero = n
for the property n we want to prove that add n Zero = n

base case: 
P(Zero) ::= add Zero Zero = Zero

add Zero Zero
v v v (apply add)
Zero

inductive case: 
P(n) => P(Succ(n)) = add n Zero = n => add (Succ n) Zero = Succ n

add (Succ (n)) Zero
v v v (Apply add)
Succ (add n Zero)
v v v (apply inducyion hypothesis: add n Zero = n)
Succ n

Example:
P(x) ::= add x (add y z) = add (add x y) z
(we take x because it occurs at the first position of the function, 
implying that it is the recursive variable)

Base case: 
P(Zero) ::= add Zero (add y z) = add (add Zero y) z

add Zero (add y z)
v v v (Apply outer add)
add y z
v v v (unapplying (inner) add)
add (add Zero y) z

add (add Zero y) z
v v v (apply inner add)
add y z 
v v v (unapplying (outer) add)
add Zero (add y z)

inductive case: 
(Start with the property that looks the most complicated)
P(x) => P(Succ x) ::= 
add x (add y z) = add (add x y) z => add (Succ x) (add y z) = add (add (Succ x) y) z

add (Succ x) (add y z)
v v v (apply outer add)
Succ (add x (add y z))
v v v (apply induction hypothesis: add x (add y z) = add (add x y) z)
Succ (add (add x y) z)
v v v (unapply outer add)
add (Succ (add x y)) z
v v v  (unnapply inner add)
add (add (Succ x) y) z

16.5

Base cases for inductive proof on lists is the property with the empty list and 
the inductive case is the property with the non-empty list.
P(xs) -> P([]) & P(xs) => P(x:xs)

Example:

rev :: [a] -> [a]
rev [] = []
rev (x:xs) = rev xs ++ [x]

show that:
rev (rev xs) = xs

Base case: 
P([]) ::= rev (rev []) = []

rev (rev [])
v v v (apply inner rev)
rev []
v v v (apply rev)
[]

inductive case:
P(xs) => P(x:xs) ::= rev (rev xs) = xs => rev (rev (x:xs)) = x:xs

rev (rev (x:xs))
v v v (apply inner rev)
rev (rev xs ++ [x])
v v v (distributivity-lemma*)
rev [x] ++ rev (rev xs)
v v v (rev of a singleton is just the same singletion -> singleton-lemma*)
[x] ++ rev (rev xs)
v v v (apply inductive hypothesis)
[x] ++ xs
v v v (apply (++))
(x:xs)

distributivity-lemma*:
rev (xs ++ ys) = rev ys ++ rev xs

{singleton-lemma*
rev [x]
v v v (extend the singletion with :)
rev (x : [])
v v v (apply rev)
rev [] ++ [x]
v v v (apply rev)
[] ++ [x]
v v v (apply (++))
[x]
}

16.6
(++) :: [a] -> [a] -> [a]
[] ++ ys = ys
(x:xs) ++ ys = x : (xs ++ ys)

reverse :: [a] -> [a]
reverse [] = []
reverse (x:xs) = reverse xs ++ [x]

How many steps does xs ++ ys take?

Example: How many steps does xs ++ ys take?
[1,2] ++ [3] 
v v v (apply ++)
1 : ([2] ++ [3]) 
v v v (apply ++)
1 : (2 : ([] ++ [3]))
v v v (apply ++)
1 : (2 : [3])

3 evaluation steps, i.e the number of evaluation steps that it would take to 
evaluate xs ++ ys is: length xs + 1 step

Example: How many steps does reverse xs take?
reverse [1,2]
v v v (apply reverse)
reverse [2] ++ [1]
v v v (apply reverse)
(reverse [] ++ [2]) ++ [1]
v v v (apply reverse)
([] ++ [2]) ++ [1]

We already discovered how meny steps an arbitrary append (++) takes and we can see
that it took 3 steps to evaluate the reverse (to finish its recursion, not to 
completion). the append consists of ([] ++ [2]), which equals to 1 step. 
After that evaluation, [2] ++ [1], it should take 1 + 1 = 2 steps.
So in the example we know that it should take 3 + 2 = 5 steps. 
In conclusion reverse xs generaly takes: 
    1 + 2 + ... + (n + 1), where n = length xs
    to find the sum of the expresion we use the sumation formula: 
    ∑ i = m(m + 1)/2, where m starts with 1 and ends with an arbitrary natural nbr.
    when we plugg in (n + 1) in m, we get:
    (n+1)(n+2)/2 = (n^2 + 3n + 2)/2

The problem with the nbr of evaluations in the reverse is now that the number of 
evaluation steps is now exponential, which lead sto it being difficult (takes time)
to evaluate the reverse of longer lists. 

We can remove the append to make this better!

Example: Removing the (++)
(this is not the definition of the function, just a spesification)
reverse' xs ys = (reverse xs) ++ ys

we use constructive induction to define the spesification.

Base case: xs is empty

reverse' [] ys
v v v (apply the equasion)
(reverse []) ++ ys
v v v (apply reverse)
[] ++ ys
v v v (apply ++)
ys

reverse' [] ys = ys

inductive case:

reverse' (x:xs) ys
v v v (apply equasion)
(reverse (x:xs)) ++ ys
v v v (apply reverse)
(reverse xs ++ [x]) ++ ys
v v v (apply assosiativity of ++)
reverse xs ++ ([x] ++ ys)
v v v (apply inner ++)
reverse xs ++ (x : ([] ++ ys))
v v v (apply inner ++)
reverse xs ++ (x : ys)
v v v (unapply equasion: reverse' xs ys = (reverse xs) ++ ys)
reverse' xs (x:ys)

we have now calcualted the base case and the inductive case,
which gives us the recursive definition for the function reverse':
reverse' :: [a] -> [a] -> [a]
reverse' [] ys = ys
reverse' (x:xs) ys = reverse' xs (x:ys)

we can now create a more efficiant reverse:
reverse :: [a] -> [a]
reverse xs = reverse' xs []

Example: using our new reverse function
reverse [1,2,3]
v v v (apply reverse)
reverse' [1,2,3] []
v v v (apply reverse')
reverse' [2,3] (1:[])
v v v (apply reverse')
reverse' [3] (2:1:[])
v v v (apply reverse')
reverse' [] (3:2:1:[])
v v v (apply reverse')
(3:2:1:[]) = [3,2,1]

in the reverse' function we recursivly append the first elemernt of xs to the 
accumulator ys. Making the new function reverse linear, instead of exponential.
The new reverse function takes: length xs + 2 steps. 


Example: another example of the elimination of append

data Tree = Leaf Int | Node Tree Tree

flatten :: Tree -> [Int]
flatten (Leaf n) = [n]
flatten (Node l r) = flatten l ++ flatten r

We want to create a more effectiv flatten function

flatten’ t ns = flatten t ++ ns

Base case: t = (Lead n)

flatten' (Leaf n) ns 
v v v (apply equality: flatten’ t ns = flatten t ++ ns)
flatten (Leaf n) ++ ns
v v v (apply flatten)
[n] ++ ns
v v v (apply ++)
(n : ([] ++ ns))
v v v (apply ++)
(n : ns)

flatten' (Leaf n) ns = n : ns

Inductive case: t = (Node l r)

flatten' (Node l r) ns 
v v v (apply flatten')
flatten (Node l r) ++ ns
v v v (apply flatten)
(flatten l ++ flatten r) ++ ns
v v v (apply assosiativity of ++)
flatten l ++ (flatten r ++ ns)
v v v (apply inductive hypothesis: flatten’ t ns = flatten t ++ ns, to r)
flatten l ++ flatten' r ns
v v v (apply inductive hypothesis to l, bcuz flatten' returns a list)
flatten' l (flatten' r ns)

flatten' (Node l r) ns = flatten' l (flatten' r ns)

we can now se how the function flatten' can be defined:
flatten' :: Tree -> [Int] -> [Int] 
flatten' (Leaf n) ns = n : ns
flatten' (Node l r) ns = flatten' l (flatten' r ns)

and the flatten function can be redefined as:
flatten :: Tree -> [Int]
flatten t = flatten' t []
where ns is the accumulator

16.7
data Expr = Val Int | Add Expr Expr
type Stack = [Int]
type Code = [Op]
data Op = PUSH Int | ADD
            deriving Show

eval :: Expr -> Int
eval (Val n) = n
eval (Add x y) = eval x + eval y

-- compile
comp :: Expr -> Code 
comp (Val n) = [PUSH n]
comp (Add x y) = comp x ++ comp y ++ [ADD]

exec :: Code -> Stack -> Stack
exec [] s = s
exec (PUSH n : c) s = exec c (n : s)
exec (ADD : c) (m : n : s) = exec c (n+m : s)

Show that the equasion exec (comp e) s = eval e : s is true for an arbitrary 
expresion e
    Inductive hypothesis: exec (comp e) s = eval e : s

Base case: e = Val n

exec (comp (Val n)) s 
v v v (apply comp)
exec ([PUSH n]) s
v v v (apply exec)
exec [] (n : s)
v v v (apply exec)
n : s 
v v v (unapply eval)
eval (Val n) : s

exec (comp (Val n)) s = eval (Val n) : s

inductive case: e = Add x y 

exec (comp (Add x y)) s 
v v v (apply comp)
exec (comp x ++ comp y ++ [ADD]) s
v v v (apply bracets around right half in exec)
exec (comp x ++ (comp y ++ [ADD])) s
v v v (apply distributivity-lemma*)
exec (comp y ++ [ADD]) (exec (comp x) s)
v v v (apply inductive hypothesis on exec (comp x) s)
exec (comp y ++ [ADD]) (eval x : s)
v v v (apply distributivity-lemma*, because (eval x : s) is our stack)
exec [ADD] (exec (comp y) (eval x : s))
v v v (apply inductive hypothesis on y)
exec [ADD] (eval y : eval x : s)
v v v (apply exec)
exec [] (eval y + eval x : s)
v v v (apply exec)
eval x + eval y : s
v v v (unapply eval)
eval (Add x y) : s

distributivity-lemma*:
exec (c ++ d) s = exec d (exec c s)


We will re-write our compiler to get a more effisient way to evaluate expresions. 

comp :: Expr -> Code 
comp e = comp' e []

comp' :: Expr -> Code -> Code
comp' (Val n) c = PUSH n : c
comp' (Add x y) c = comp' x (comp' y (ADD : c))

We can redefine comp e = comp’ e []

Inductive hypothesis: exec (comp’ e c) s = exec c (eval e : s)

Base case: e = Val n 
exec (comp’ (Val n) c) s
v v v (apply comp')
exec (PUSH n : c) s
v v v (apply exec)
exec c (n : s)
v v v (unapply eval)
exec c (eval (Val n) : s)


inductive case: e = Add x y 
exec (comp’ (Add x y) c) s
v v v (apply comp')
exec (comp' x (comp' y (ADD : c))) s 
v v v (apply induction hypothesis for x)
exec (comp' y (ADD : c)) (eval x : s)
v v v (apply induction hypothesis for y)
exec (ADD : c) (eval y : eval x : s)
v v v (apply exec)
exec c (eval x + eval y : s)
v v v (unapply eval)
exec c (eval (Add x y) : s)

Benefits:
- redused the number of steps in the induction. 
- no lemmas are now needed (that require further proof).
- append (++) has now vanished.
- the stack underflow problem (in the distributivity-lemma*) has now also vanished.